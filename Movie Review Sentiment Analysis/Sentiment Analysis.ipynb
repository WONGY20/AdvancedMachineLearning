{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW5: Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Embeddings models: Glove\n",
    "\n",
    "$$ \\sum ^{m}_{i=1}\\sum ^{m}_{j=1}f\\left( X_{ij}\\right) \\left( \\theta _{i}e_{i}+b'j-\\log(X_{ij})\\right) ^{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Prameters\n",
    "\n",
    "$$ \\theta_{i},  e_{j},  b_{i},  b'_{j}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Number of Parameters\n",
    "\n",
    "$$ 2 \\times D\\times M + 2 \\times M = 2M(D+1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Embeeding models: Skip-gram or word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Parameters:\n",
    "\n",
    "$$ \\theta_{j}, e_{c} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 We minimize log-function:\n",
    "\n",
    "$$ \\ell = -\\sum_{i=1}^{M} y_{i} log( \\hat{y_{i}} )$$\n",
    "\n",
    "where $y_{i}$ is a $1 \\times M$ vector whose cell euqals to 1 for $i^{th}$ position and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis with word embedings\n",
    "classify movie reviews into positive and negative. The large movie view dataset (http://ai.stanford.edu/~amaas/data/sentiment/) contains a collection of 50,000 reviews from\n",
    "IMDB. The dataset contains an even number of positive and negative re-\n",
    "views.The dataset is divided into training and test sets. The training set is\n",
    "the same 25,000 labeled reviews. The sentiment classication task consists\n",
    "of predicting the polarity (positive or negative) of a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "%matplotlib inline\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-02-22 22:04:21--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "Resolving ai.stanford.edu... 171.64.68.10\n",
      "Connecting to ai.stanford.edu|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 84125825 (80M) [application/x-gzip]\n",
      "Saving to: 'aclImdb_v1.tar.gz'\n",
      "\n",
      "aclImdb_v1.tar.gz   100%[===================>]  80.23M  15.3MB/s    in 5.2s    \n",
      "\n",
      "2018-02-22 22:04:55 (15.4 MB/s) - 'aclImdb_v1.tar.gz' saved [84125825/84125825]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**unzip the file in the local directory**\n",
    "\n",
    "`gunzip aclImdb_v1.tar.gz`\n",
    "\n",
    "`tar -xvf aclImdb_v1.tar`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH='aclImdb/'\n",
    "names = ['neg','pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeledBow.feat  \u001b[34mpos\u001b[m\u001b[m/             unsupBow.feat    urls_pos.txt\r\n",
      "\u001b[34mneg\u001b[m\u001b[m/             \u001b[34munsup\u001b[m\u001b[m/           urls_neg.txt     urls_unsup.txt\r\n"
     ]
    }
   ],
   "source": [
    "%ls aclImdb/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# source: fastai library\n",
    "def texts_labels_from_folders(path, folders):\n",
    "    texts,labels = [],[]\n",
    "    for idx,label in enumerate(folders):\n",
    "        for fname in glob(os.path.join(path, label, '*.*')):\n",
    "            texts.append(open(fname, 'r').read())\n",
    "            labels.append(idx)\n",
    "    return texts, np.array(labels).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.1 s, sys: 719 ms, total: 2.82 s\n",
      "Wall time: 2.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trn,trn_y = texts_labels_from_folders(f'{PATH}train',names)\n",
    "val,val_y = texts_labels_from_folders(f'{PATH}test',names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000, 25000, 25000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn), len(trn_y), len(val), len(val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Use the libary spacy to tokenize your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import string\n",
    "import re\n",
    "from spacy.symbols import ORTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first time run this\n",
    "#!python3 -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# borrowed from fast.ai (https://github.com/fastai/fastai/blob/master/fastai/nlp.py)\n",
    "\n",
    "re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
    "def sub_br(x): return re_br.sub(\"\\n\", x)\n",
    "\n",
    "my_tok = spacy.load('en')\n",
    "def spacy_tok(x): \n",
    "    #x = x\n",
    "    return [tok.text.lower() for tok in my_tok.tokenizer(sub_br(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This film lacked something I couldn't put my finger on at first: charisma on the part of the leading actress. This inevitably translated to lack of chemistry when she shared the screen with her leading man. Even the romantic scenes came across as being merely the actors at play. It could very well have been the director who miscalculated what he needed from the actors. I just don't know.<br /><br />But could it have been the screenplay? Just exactly who was the chef in love with? He seemed more enamored of his culinary skills and restaurant, and ultimately of himself and his youthful exploits, than of anybody or anything else. He never convinced me he was in love with the princess.<br /><br />I was disappointed in this movie. But, don't forget it was nominated for an Oscar, so judge for yourself.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'film', 'lacked', 'something', 'i', 'could', \"n't\", 'put', 'my', 'finger', 'on', 'at', 'first', ':', 'charisma', 'on', 'the', 'part', 'of', 'the', 'leading', 'actress', '.', 'this', 'inevitably', 'translated', 'to', 'lack', 'of', 'chemistry', 'when', 'she', 'shared', 'the', 'screen', 'with', 'her', 'leading', 'man', '.', 'even', 'the', 'romantic', 'scenes', 'came', 'across', 'as', 'being', 'merely', 'the', 'actors', 'at', 'play', '.', 'it', 'could', 'very', 'well', 'have', 'been', 'the', 'director', 'who', 'miscalculated', 'what', 'he', 'needed', 'from', 'the', 'actors', '.', 'i', 'just', 'do', \"n't\", 'know', '.', '\\n\\n', 'but', 'could', 'it', 'have', 'been', 'the', 'screenplay', '?', 'just', 'exactly', 'who', 'was', 'the', 'chef', 'in', 'love', 'with', '?', 'he', 'seemed', 'more', 'enamored', 'of', 'his', 'culinary', 'skills', 'and', 'restaurant', ',', 'and', 'ultimately', 'of', 'himself', 'and', 'his', 'youthful', 'exploits', ',', 'than', 'of', 'anybody', 'or', 'anything', 'else', '.', 'he', 'never', 'convinced', 'me', 'he', 'was', 'in', 'love', 'with', 'the', 'princess', '.', '\\n\\n', 'i', 'was', 'disappointed', 'in', 'this', 'movie', '.', 'but', ',', 'do', \"n't\", 'forget', 'it', 'was', 'nominated', 'for', 'an', 'oscar', ',', 'so', 'judge', 'for', 'yourself', '.']\n"
     ]
    }
   ],
   "source": [
    "print(spacy_tok(trn[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove\n",
    "\n",
    "## 2. Download embedding vectors from https://nlp.stanford.edu/projects/glove/.\n",
    "\n",
    "## 3. Read the 300 dimensional Glove embeddings into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34maclImdb\u001b[m\u001b[m           embeddings.p      gloves.p          hw5.ipynb\r\n",
      "aclImdb_v1.tar    glove.6B.300d.txt hw-embedding.pdf\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "globe_path = \"glove.6B.300d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_word_embedings(file =globe_path):\n",
    "    embeddings = {}\n",
    "    with open(file, 'r') as infile:\n",
    "        for line in infile:\n",
    "            values = line.split()\n",
    "            embeddings[values[0]] = np.asarray(values[1:], dtype='float32')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.1 s, sys: 1.6 s, total: 29.7 s\n",
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# embeddings = load_word_embedings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle.dump( embeddings, open( \"embeddings.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.68 s, sys: 627 ms, total: 2.31 s\n",
      "Wall time: 2.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load gloves from pickle which is much faster\n",
    "embeddings = pickle.load( open( \"embeddings.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create *average* feature embedding for each sentence. You may want to ignore stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_features(s, embeddings=embeddings, emb_size=300):\n",
    "    words = spacy_tok(s)\n",
    "    words = [w for w in words if w.isalpha() and w in embeddings]\n",
    "    if len(words) == 0:\n",
    "        return np.zeros(3 * emb_size)\n",
    "    M = [embeddings[w] for w in words]\n",
    "    M = np.array(M)\n",
    "    v_mean = M.mean(axis=0)\n",
    "    v_min = M.min(axis=0)\n",
    "    v_max = M.max(axis=0)\n",
    "    return np.hstack([v_mean,v_min, v_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_features_v2(s, embeddings=embeddings, emb_size=300):\n",
    "    words = spacy_tok(s) #tokenizer\n",
    "    words = [w for w in words if w.isalpha() and w in embeddings]\n",
    "    if len(words) == 0:\n",
    "        return np.hstack([np.zeros(emb_size)])\n",
    "    M = np.array([embeddings[w] for w in words])\n",
    "    return M.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.5 s, sys: 279 ms, total: 39.8 s\n",
      "Wall time: 40 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create sentence vectors \n",
    "x_train = np.array([sentence_features_v2(i) for i in trn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.2 s, sys: 234 ms, total: 36.4 s\n",
      "Wall time: 36.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_val = np.array([sentence_features_v2(i) for i in val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fit an XGBoost classifier to this data. Report test and training errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.687224\tvalid-logloss:0.687575\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.465641\tvalid-logloss:0.49207\n",
      "[200]\ttrain-logloss:0.399465\tvalid-logloss:0.441601\n",
      "[300]\ttrain-logloss:0.363565\tvalid-logloss:0.416341\n",
      "[400]\ttrain-logloss:0.339773\tvalid-logloss:0.401955\n",
      "[500]\ttrain-logloss:0.32184\tvalid-logloss:0.392844\n",
      "[600]\ttrain-logloss:0.307297\tvalid-logloss:0.386234\n",
      "[700]\ttrain-logloss:0.295013\tvalid-logloss:0.381361\n",
      "[800]\ttrain-logloss:0.284476\tvalid-logloss:0.378237\n",
      "[900]\ttrain-logloss:0.275189\tvalid-logloss:0.37578\n",
      "[1000]\ttrain-logloss:0.266685\tvalid-logloss:0.373537\n",
      "[1100]\ttrain-logloss:0.258645\tvalid-logloss:0.372101\n",
      "[1200]\ttrain-logloss:0.251643\tvalid-logloss:0.371093\n",
      "[1300]\ttrain-logloss:0.244961\tvalid-logloss:0.370306\n",
      "[1400]\ttrain-logloss:0.23872\tvalid-logloss:0.36965\n",
      "[1500]\ttrain-logloss:0.232907\tvalid-logloss:0.369013\n",
      "[1600]\ttrain-logloss:0.227371\tvalid-logloss:0.368874\n",
      "Stopping. Best iteration:\n",
      "[1524]\ttrain-logloss:0.231591\tvalid-logloss:0.368852\n",
      "\n",
      "CPU times: user 14min 21s, sys: 8.57 s, total: 14min 30s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d_train = xgb.DMatrix(x_train, label=trn_y)\n",
    "d_val = xgb.DMatrix(x_val, label=val_y)\n",
    "\n",
    "xgb_pars = {\"min_child_weight\": 100, \"eta\": 0.03, \"max_depth\": 8,\n",
    "            \"subsample\": 0.5, \"silent\" : 1, \"colsample_bytree\": 0.4,\n",
    "            \"nthread\": 8,\n",
    "            \"eval_metric\": \"logloss\", \"objective\": \"binary:logistic\"}\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_val, 'valid')]\n",
    "\n",
    "bst = xgb.train(xgb_pars, d_train, 2000, watchlist, early_stopping_rounds=100, verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83543999999999996"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = bst.predict(d_val)\n",
    "y_pred = [round(i) for i in y_pred]\n",
    "\n",
    "sum(y_pred == val_y)/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83660000000000001"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression benchmark\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "m = LogisticRegression(C=10, dual=True)\n",
    "m.fit(x_train, trn_y)\n",
    "preds = m.predict(x_val)\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare previous results to \f",
    "tting XGBoost to a one-hot encoding\n",
    "representation of the data with bag of words. Report test and training\n",
    "errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.26 s, sys: 163 ms, total: 8.42 s\n",
      "Wall time: 8.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "freq = CountVectorizer()\n",
    "x_train_ = freq.fit_transform(trn)\n",
    "x_val_ = freq.transform(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.681089\tvalid-logloss:0.681198\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.411805\tvalid-logloss:0.432926\n",
      "[200]\ttrain-logloss:0.345302\tvalid-logloss:0.381341\n",
      "[300]\ttrain-logloss:0.307416\tvalid-logloss:0.356062\n",
      "[400]\ttrain-logloss:0.282342\tvalid-logloss:0.341037\n",
      "[500]\ttrain-logloss:0.262916\tvalid-logloss:0.331188\n",
      "[600]\ttrain-logloss:0.247591\tvalid-logloss:0.324449\n",
      "[700]\ttrain-logloss:0.235224\tvalid-logloss:0.319576\n",
      "[800]\ttrain-logloss:0.223943\tvalid-logloss:0.316036\n",
      "[900]\ttrain-logloss:0.21466\tvalid-logloss:0.313344\n",
      "[1000]\ttrain-logloss:0.205895\tvalid-logloss:0.311312\n",
      "[1100]\ttrain-logloss:0.198509\tvalid-logloss:0.309834\n",
      "[1200]\ttrain-logloss:0.191528\tvalid-logloss:0.308789\n",
      "[1300]\ttrain-logloss:0.184958\tvalid-logloss:0.308111\n",
      "[1400]\ttrain-logloss:0.178524\tvalid-logloss:0.307511\n",
      "[1500]\ttrain-logloss:0.172735\tvalid-logloss:0.307153\n",
      "[1600]\ttrain-logloss:0.167726\tvalid-logloss:0.307141\n",
      "Stopping. Best iteration:\n",
      "[1568]\ttrain-logloss:0.169533\tvalid-logloss:0.306924\n",
      "\n",
      "CPU times: user 57min 33s, sys: 3min 43s, total: 1h 1min 16s\n",
      "Wall time: 8min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d_train = xgb.DMatrix(x_train_, label=trn_y)\n",
    "d_val = xgb.DMatrix(x_val_, label=val_y)\n",
    "\n",
    "xgb_pars = {\"min_child_weight\": 50, \n",
    "            \"eta\": 0.05, \n",
    "            \"max_depth\": 8,\n",
    "            #\"subsample\": 0.5, \n",
    "            \"silent\" : 1, \n",
    "            #\"colsample_bytree\": 0.4,\n",
    "            \"nthread\": 8,\n",
    "            \"eval_metric\": \"logloss\", \"objective\": \"binary:logistic\"}\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_val, 'valid')]\n",
    "\n",
    "bst = xgb.train(xgb_pars, d_train, 2000, watchlist, early_stopping_rounds=100, verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86695999999999995"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = bst.predict(d_val)\n",
    "y_pred = [round(i) for i in y_pred]\n",
    "\n",
    "sum(y_pred == val_y)/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85940000000000005"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression benchmark\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "m = LogisticRegression(C=10, dual=True)\n",
    "m.fit(x_train_, trn_y)\n",
    "preds = m.predict(x_val_)\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "* https://www.kaggle.com/anokas/data-analysis-xgboost-starter-0-35460-lb\n",
    "* https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle/\n",
    "* https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
